/**
 * @generated
 */
module.exports = [
  {
    "path": "2020/08/01/blog-post.html",
    "content": "\n`Doodler` can work with really large images, but it is usually best to keep your images < 10,000 pixels in any dimension, because then the program will do CRF inference on the whole image at once rather than in chunks. This usually results in better image segmentations that are more consistent with your doodles.\n\nSo, this post is all about how you make smaller image tiles from a very large geoTIFF format orthomosaic, using python. The smaller tiles will also be written out as image tiles, with their relative position in the larger image described in the file name, for easy reassembly\n\nWe'll need a dependency not included in the `doodler` environment: `gdal`\n\n`conda install gdal`\n\nNow, in python:\n\n```\nimport os, gdal\nfrom gdalconst import *\nfrom glob import glob\n```\n\nHow large do you want your output (square) image tiles to be? (in pixels)\n\n```\ntilesize = 5000\n```\n\nWhat images would you like to chop up?\n\n```\nbigfiles = [\n'Sandwich/2017-01-09_Sandwich_5cm_ortho.tif',\n'Sandwich/2017-02-14_Sandwich_5cm_ortho.tif',\n'Sandwich/2017-03-16_Sandwich_5cm_ortho.tif',\n'Sandwich/2018-01-10_Sandwich_5cm_ortho.tif',\n]\n```\n\nList the widths and heights of those input `bigfiles`\n\n```\nwidths = [13314, 13314, 13314, 19972]\nheights = [6212, 6212, 6212, 9319]\n```\n\nSpecify a new folder for each set of image tiles (one per big image)\n\n```\nfolders = ['Sandwich/2017-01-09_5cm', 'Sandwich/2017-02-14_5cm',\\\n          'Sandwich/2017-03-16_5cm','Sandwich/2017-01-10_5cm']\n```\n\nMake file name prefixes by borrowing the folder name:\n\n```\nprefixes = [f.split('/')[-1] for f in folders]\n```\n\nFinally, loop through each file, chop it into chunks using `gdal_translate`, called by an `os.system()` command. Then moves the tiles into their respective folders\n\n```\nfor b,f,p in zip(bigfiles, folders, prefixes):\n\n    # chop the image into chunks\n    for i in range(0, widths[k], tilesize):\n        for j in range(0, heights[k], tilesize):\n            gdaltranString = \"gdal_translate -of GTIFF -srcwin \"+str(i)+\", \"+str(j)+\", \"+str(tilesize)+\", \" \\\n                +str(tilesize)+\" \"+b+\" \"+p+\"_\"+str(i)+\"_\"+str(j)+\".tif\"\n            os.system(gdaltranString)\n\n    ##move those chunks to a directory\n    os.mkdir(f)\n    os.system('mv '+p+'*.tif '+f)\n```\n",
    "title": "Splitting up large geoTIFF orthomosaics",
    "author": "Dan Buscombe",
    "authorURL": "http://twitter.com/magic_walnut",
    "id": "Splitting up large geoTIFF orthomosaics",
    "date": "2020-08-01T06:00:00.000Z",
    "seconds": 1596261600
  },
  {
    "path": "2020/07/31/blog-post.html",
    "content": "\n`Doodler` can use 1, 3, and 4-band input imagery. If the imagery is 3-band, it is assumed to be RGB and is, by default, augmented with 3 additional derivative bands.\n\nBut how do you make a 4-band image from a 3-band image and a 1-band image?\n\nThat additional 1-band might be that acquired with an additional sensor, but might more commonly be a DEM (Digital Elevation Model) corresponding to the scene.\n\nI know of two ways. If you have `gdal` binaries installed, first strip the image into its component bands using `gdal_translate`\n```\ngdal_translate -b 1 data/images/4_rgb.png red.png\ngdal_translate -b 2 data/images/4_rgb.png green.png\ngdal_translate -b 3 data/images/4_rgb.png blue.png\n```\n\nThen merge them together using `gdal_merge.py`\n\n```\ngdal_merge.py -separate -o merged.tiff -co PHOTOMETRIC=MINISBLACK red.png green.png blue.png data/images/4_elev.png\n```\n\nThe equivalent in python can be acheived without the `gdal` bindings, using the libraries already in your `doodler` conda environment\n\nFirst, import libraries\n\n```\nimport tifffile\nimport cv2\nimport numpy as np\n```\n\nRead RGB image\n\n```\nim1 = cv2.imread('data/images/4_rgb.png')\n```\n\nRead elevation and get just the first band (if this is 3-band)\n\n```\nim2 = cv2.imread('data/images/4_elev.png')[:,:,0]\n```\n\nIf you had a 1-band elevation image, it would be this instead...\n\n```\nim2 = cv2.imread('data/images/4_elev.png')\n```\n\nMerge bands - creates a numpy array with 4 channels\n\n```\nmerged = np.dstack((im1, im2))\n```\n\nWrite the image to file\n\n```\ntifffile.imsave('test.tiff', merged)\n```\n\nYou can use the following to read it back in\n\n```\nmerged = tifffile.imread('test.tiff')\n```\n\nAnd verify with 'shape' - it should be 4 bands\n\n```\nmerged.shape\n```\n",
    "title": "merge a 3-band and 1-band image",
    "author": "Dan Buscombe",
    "authorURL": "http://twitter.com/magic_walnut",
    "id": "merge a 3-band and 1-band image",
    "date": "2020-07-31T06:00:00.000Z",
    "seconds": 1596175200
  },
  {
    "path": "2020/07/30/blog-post.html",
    "content": "\n Spaces in image file names are problematic for the program because it uses filename string subsections to match images to outputs. White space is the escape character for most programming languages.\n\n A one-liner for replacing white spaces with underscores in bash is\n\n `find -name \"* *\" -type f | rename 's/ /_/g'`\n\n The above command will replace spaces with underscores. Make a copy of your images beforehand for extra caution. The above code is a bash command, so on Windows you'd need [git bash](https://gitforwindows.org/), [WSL](https://docs.microsoft.com/en-us/windows/wsl/install-win10), or have m2-base installed (`conda install m2-base`)\n",
    "title": "no spaces in filenames!",
    "author": "Dan Buscombe",
    "authorURL": "http://twitter.com/magic_walnut",
    "id": "no spaces in filenames!",
    "date": "2020-07-30T06:00:00.000Z",
    "seconds": 1596088800
  },
  {
    "path": "2020/07/29/blog-post.html",
    "content": "If you want to redo all your previous doodles with the new doodler, put all your images in data/images and put the npy files in data/label_images. Then you can call doodler like this in a loop:\n\n```\nfor file in data/label_images/*.npy\ndo python doodler.py -c config.json -f $file\ndone\n```\n\nand it will cycle through each of the npy annotations, make a new label and probability image based on the current version of the CRF inference encoded in the main program.\n\nThe above code is a bash command, so on Windows you'd need [git bash](https://gitforwindows.org/), [WSL](https://docs.microsoft.com/en-us/windows/wsl/install-win10), or have m2-base installed (`conda install m2-base`)\n",
    "title": "batch \"redoing\"",
    "author": "Dan Buscombe",
    "authorURL": "http://twitter.com/magic_walnut",
    "id": "batch \"redoing\"",
    "date": "2020-07-29T06:00:00.000Z",
    "seconds": 1596002400
  }
];
